FROM: Ivan Provalov <iprov...@yahoo.com>
SUBJECT: TREC-3 Runs
DATE: 12 Mar 2010

Just to follow up on our previous discussion, here are a few runs in which we have tested some
of the Lucene different scoring mechanisms and other options.  We used Lucene's patches for
LnbLtcSimilarity and BM25 and contrib module for the SweetSpotSimilarity.

Lucene Default:	0.149
Lucene BM25: 	0.168
SweetSpotSimilarity (Min: 10; Max: 1000; Steepness: 0.2): 0.173
LnbLtcSimilarity (Pivot Norm + TF Default; Avg # of Terms: 450; slope: 0.25):	0.184
LnbLtcSimilarity (Pivot Norm + TF Log; Avg # of Terms: 450; slope: 0.25):	0.186
Lucene With Stemmer: 0.202
Lucene With Lexical Affinities + Phrase Expansion + Stemmer: 0.21

Thanks,

Ivan



      

---------------------------------------------------------------------
To unsubscribe, e-mail: java-user-unsubscribe@lucene.apache.org
For additional commands, e-mail: java-user-help@lucene.apache.org


