FROM: Michael McCandless <luc...@mikemccandless.com>
SUBJECT: Re: Flex API - Debugging Segment Merge
DATE: 27 Mar 2010

Phew, I'm glad to hear you got to the bottom of it!  Good sleuthing.

And I'm looking forwarded to your results and hopefully patches that
make these various encoding techniques available as flex codecs :)

Mike

On Fri, Mar 26, 2010 at 6:08 PM, Renaud Delbru <renaud.delbru@deri.org> wrote:
> Hi Michael,
>
> On 25/03/10 19:15, Michael McCandless wrote:
>>>
>>> I am using one single thread for indexing: reading sequentially the list
>>> of
>>> wikipedia articles, putting the content into a single field, and add the
>>> document to the index. Commit is done every 10K documents.
>>>
>>
>> Are you using contrib/benchmark for this? Â That makes it very easy to
>> run tests like this... hmm though we need to extend it so you can
>> specify which Codec to use...
>>
>
> No, I have implemented a simple benchmark platform for measuring indexing
> time and query time. But indeed, I saw that you have a wikipedia extractor,
> this could have save us some time.
>>
>> You can instrument the code (or catch the exc in a debugger) to see
>> all these details?
>>
>
> Yes, I did that today, and finally got all the information I needed to find
> the problems.
> It was indeed a bug in my PFor implementation, that was occurring only in
> very rare cases.
>
> I'll start the query benchmark this week end. Let's hope I'll have something
> to share during the next week.
>
> Cheers
> --
> Renaud Delbru
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: java-user-unsubscribe@lucene.apache.org
> For additional commands, e-mail: java-user-help@lucene.apache.org
>
>

---------------------------------------------------------------------
To unsubscribe, e-mail: java-user-unsubscribe@lucene.apache.org
For additional commands, e-mail: java-user-help@lucene.apache.org


