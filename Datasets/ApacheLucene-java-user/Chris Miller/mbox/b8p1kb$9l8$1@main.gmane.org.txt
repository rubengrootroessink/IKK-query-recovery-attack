FROM: "Chris Miller" <ch...@swebtec.com>
SUBJECT: Performance with a highly dynamic index
DATE: 30 Apr 2003

I would like to be able to search against roughly 100,000 documents, with
each document containing roughly 10 fields, only 1 or 2 of which will be
blocks of plain english text (the rest will be set up for range queries,
keywords and the like). Each document will contain around 5KB - 10KB of
text.

So far so good right? I'm confident Lucene can handle far greater volumes
than that as far as searching goes.

But... these documents will be changing quite rapidly, on the order of
50,000 changes/day (a combination of updates/deletes/inserts). I'd like to
be able to constantly update these documents in real-time while still being
able to search against them fairly heavily.

Does this sound feasible or should I not even be attempting this? Are there
any gotchas I should be aware of? If anyone has some real-world experience
with this scenario I'd _really_ appreciate a few comments as to how well
your implementation performs.




---------------------------------------------------------------------
To unsubscribe, e-mail: lucene-user-unsubscribe@jakarta.apache.org
For additional commands, e-mail: lucene-user-help@jakarta.apache.org


