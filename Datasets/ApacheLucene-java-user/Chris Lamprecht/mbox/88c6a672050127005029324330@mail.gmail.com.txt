FROM: Chris Lamprecht <clampre...@gmail.com>
SUBJECT: Re: Searching with words that contain % , / and the like
DATE: 27 Jan 2005

Without looking at the source, my guess is that StandardAnalyzer (and
StandardTokenizer) is the culprit.  The StandardAnalyzer grammar (in
StandardTokenizer.jj) is probably defined so "x/y" parses into two
tokens, "x" and "y".  "s" is a default stopword (see
StopAnalyzer.ENGLISH_STOP_WORDS), so it gets filtered out, while "p"
does not.

To get what you want, you can use a WhitespaceAnalyzer, write your own
custom Analyzer or Tokenizer, or modify the StandardTokenizer.jj
grammar to suit your needs.  WhitespaceAnalyzer is much simpler than
StandardAnalyzer, so you may see some other things being tokenized
differently.

-Chris

On Thu, 27 Jan 2005 12:12:16 +0530, Robinson Raju
<robinson.raju@gmail.com> wrote:
> Hi ,
> 
> Is there a way to search for words that contain "/" or "%" .
> if my query is "test/s" , it is just taken as "test"
> if my query is "test/p" , it is just taken as "test p"
> has anyone done this / faced such an issue ?
> 
> Regards
> Robin
> 
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: lucene-user-unsubscribe@jakarta.apache.org
> For additional commands, e-mail: lucene-user-help@jakarta.apache.org
> 
>

---------------------------------------------------------------------
To unsubscribe, e-mail: lucene-user-unsubscribe@jakarta.apache.org
For additional commands, e-mail: lucene-user-help@jakarta.apache.org


