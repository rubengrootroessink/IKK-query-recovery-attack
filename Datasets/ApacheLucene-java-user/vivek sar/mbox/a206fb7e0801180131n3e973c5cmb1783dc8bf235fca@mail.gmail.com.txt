FROM: "vivek sar" <vivex...@gmail.com>
SUBJECT: Optimize for large index size
DATE: 18 Jan 2008

Hi,

  We are using Lucene 2.2. We have an index of size 70G (within 3-4
days) and growing. We run optimize pretty frequently (once every hour
- due to large number of index updates every min - can be up to 100K
new documents every min). I have seen every now and then the optimize
takes 3-4 hours to complete and up to 8 G memory (our limit). This
makes the whole system slow. Few questions,

1) Is there any alternative to optimize? That is, can we do without
optimize and still have our search fast?
2) What's the best way to use optimize, i.e. how can we make the
optimize much faster and use lesser memory?
3) Is there a way to partition the indexes using Lucene? Let's say we
partition daily, so we have to optimize only the daily indexes and not
the whole thing.

Our mergefactor=200 and maxMergeDocs=99999

Thanks,
-vivek

---------------------------------------------------------------------
To unsubscribe, e-mail: java-user-unsubscribe@lucene.apache.org
For additional commands, e-mail: java-user-help@lucene.apache.org


