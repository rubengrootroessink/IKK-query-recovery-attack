FROM: Doug Cutting <cutt...@apache.org>
SUBJECT: Re: Memory usage
DATE: 26 May 2004

James Dunn wrote:
> Also I search across about 50 fields but I don't use
> wildcard or range queries. 

Lucene uses one byte of RAM per document per searched field, to hold the 
normalization values.  So if you search a 10M document collection with 
50 fields, then you'll end up using 500MB of RAM.

If you're using unanalyzed fields, then an easy workaround to reduce the 
number of fields is to combine many in a single field.  So, instead of, 
e.g., using an "f1" field with value "abc", and an "f2" field with value 
"efg", use a single field named "f" with values "1_abc" and "2_efg".

We could optimize this in Lucene.  If no values of an indexed field are 
analyzed, then we could store no norms for the field and hence read none 
into memory.  This wouldn't be too hard to implement...

Doug

---------------------------------------------------------------------
To unsubscribe, e-mail: lucene-user-unsubscribe@jakarta.apache.org
For additional commands, e-mail: lucene-user-help@jakarta.apache.org


