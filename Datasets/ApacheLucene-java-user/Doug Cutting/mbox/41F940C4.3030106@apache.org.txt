FROM: Doug Cutting <cutt...@apache.org>
SUBJECT: Re: Opening up one large index takes 940M or memory?
DATE: 27 Jan 2005

Kevin A. Burton wrote:
> Is there any way to reduce this footprint?  The index is fully 
> optimized... I'm willing to take a performance hit if necessary.  Is 
> this documented anywhere?

You can increase TermInfosWriter.indexInterval.  You'll need to re-write 
the .tii file for this to take effect.  The simplest way to do this is 
to use IndexWriter.addIndexes(), adding your index to a new, empty, 
directory.  This will of course take a while for a 60GB index...

Doubling TermInfosWriter.indexInterval should half the Term memory usage 
and double the time required to look up terms in the dictionary.  With 
an index this large the the latter is probably not an issue, since 
processing term frequency and proximity data probably overwhelmingly 
dominate search performance.

Perhaps we should make this public by adding an IndexWriter method?

Also, you can list the size of your .tii file by using the main() from 
CompoundFileReader.

Doug

---------------------------------------------------------------------
To unsubscribe, e-mail: lucene-user-unsubscribe@jakarta.apache.org
For additional commands, e-mail: lucene-user-help@jakarta.apache.org


