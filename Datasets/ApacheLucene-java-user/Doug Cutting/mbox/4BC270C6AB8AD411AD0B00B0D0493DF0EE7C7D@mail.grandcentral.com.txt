FROM: Doug Cutting <DCutt...@grandcentral.com>
SUBJECT: RE: File Handles issue
DATE: 15 Oct 2001

> From: Scott Ganyo [mailto:scott.ganyo@eTapestry.com]
> 
> Thanks for the detailed information, Doug!  That helps a lot.
> 
> Based on what you've said and on taking a closer look at the 
> code, it looks
> like by setting mergeFactor and maxMergeDocs to 
> Integer.MAX_VALUE, an entire
> index will be built in a single segment completely in memory 
> (using the
> RAMDirectory) and then flushed to disk when closed.

Not quite.  This would generate an index with a segment per document in
memory, and then try to merge them all in a single step.  That should work,
but I do not think it is the most efficient way to build an index in memory.

> P.S. At one point I tried doing an in-memory index using the 
> RAMDirectory
> and then merging it with an on-disk index and it didn't work.  The
> RAMDirectory never flushed to disk... leaving me with an 
> empty index.  I
> think this is because of a bug in the mechanism that is 
> supposed to copy the
> segments during the merge, but I didn't follow up on this.

That should work, it should be faster and would use a lot less memory than
the approach you describe above.  Can you please submit a simple test case
illustrating the failure?  Something self-contained would be best.

Doug

