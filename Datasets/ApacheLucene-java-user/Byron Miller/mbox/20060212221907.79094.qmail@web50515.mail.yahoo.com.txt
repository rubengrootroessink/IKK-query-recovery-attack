FROM: Byron Miller <byronmh...@yahoo.com>
SUBJECT: Re: Performance and FS block size
DATE: 12 Feb 2006

I just through in the reiserfs suggestion since it's
usually nott a 1k vs 4k blocksize issue as much as it
is how many contiguous files consume those blocksizes.
If they're small and random reiserfs will smoke ext3,
if they're large ext3 will be lighter weight and if
they're really large and somewhat sequential XFS will
annihalite them all.

Were you able to see how much peak transfer your
drives get?

You have to remember on linux that unless you bypass
the kernel cache (fs buffer) and have java optimized
to cache or read its blocks then your really just
testing the performance of the linux schedular and
caching mechanism more than your 1k vs 4k blocksize.

Modern databases don't even reflect the need for
blocksize to match your db block size anymore as most
of the IO is done through enhanced kernel io
procedures and optimized to bypass the linux kernel
caching of which i'm not sure if java is capable of
doing. (haven't done any research) I'm also pretty
positive the bypassing of block buffering through the
new io libs is primarily redhat releated with other
vendors having there own version.

--- Otis Gospodnetic <otis_gospodnetic@yahoo.com>
wrote:

> Hi,
> 
> I'm somewhat familiar with ext3 vs. ReiserFS stuff,
> but that's not really what I'm after (finding a
> better/faster FS).  What I'm wondering is about
> different block sizes on a single (ext3) FS.
> If I understand block sizes correctly, they
> represent a chunk of data that the FS will read in a
> single read.


---------------------------------------------------------------------
To unsubscribe, e-mail: java-user-unsubscribe@lucene.apache.org
For additional commands, e-mail: java-user-help@lucene.apache.org


