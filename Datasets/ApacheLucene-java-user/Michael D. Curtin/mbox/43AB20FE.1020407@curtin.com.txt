FROM: "Michael D. Curtin" <m...@curtin.com>
SUBJECT: Re: OutOfMemory during optimize
DATE: 22 Dec 2005

Steve Rajavuori wrote:
> I am periodically getting "Too many open files" error when searching. Currently there
are over 500 files in my Lucene directory. I am attempting to run optimize( ) to reduce the
number of files. However, optimize never finishes because whenever I run it, it quits with
a Java exception OutOfMemory error. I have tried using the -Xmx and -Xms switches to increase
heap size, but that has not helped.
>  
> Any suggestions?

What is mergeFactor set to in your IndexWriter?  Decreasing it makes 
optimize() take longer, but use less memory.  How much RAM does the 
machine you're running on have, compared to the size of your index's 
documents?

--MDC

---------------------------------------------------------------------
To unsubscribe, e-mail: java-user-unsubscribe@lucene.apache.org
For additional commands, e-mail: java-user-help@lucene.apache.org


