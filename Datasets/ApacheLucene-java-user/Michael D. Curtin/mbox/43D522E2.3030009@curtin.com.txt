FROM: "Michael D. Curtin" <m...@curtin.com>
SUBJECT: Re: OutOfMemory during optimize
DATE: 23 Jan 2006

Steve Rajavuori wrote:
> I am periodically getting "Too many open files" error when searching. Currently there
are over 500 files in my Lucene directory. I am attempting to run optimize( ) to reduce the
number of files. However, optimize never finishes because whenever I run it, it quits with
a Java exception OutOfMemory error. I have tried using the -Xmx and -Xms switches to increase
heap size, but that has not helped.
> 
> Any suggestions?

You could try reducing maxMergeDocs and mergeFactor.  Doing so increases 
the time it takes to optimize, but reduces the amount of memory consumed.

Good luck!

--MDC

---------------------------------------------------------------------
To unsubscribe, e-mail: java-user-unsubscribe@lucene.apache.org
For additional commands, e-mail: java-user-help@lucene.apache.org


