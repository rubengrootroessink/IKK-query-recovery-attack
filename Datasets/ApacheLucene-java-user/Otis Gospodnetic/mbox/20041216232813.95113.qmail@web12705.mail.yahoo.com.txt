FROM: Otis Gospodnetic <otis_gospodne...@yahoo.com>
SUBJECT: Re: Why does the StandardTokenizer split hyphenated words?
DATE: 16 Dec 2004

Hello,

As Erik already said - that Analyzer is really there to get people
going quickly and as a 'does pretty good' Analyzer.  There is no
Analyzer that will work for everyone, and Analyzers are meant to be
custom-made.  It looks like you already got that figured out and have
your own Analyzer.

Otis

--- Mike Snare <mikesnare@gmail.com> wrote:

> Absolutely, but -- correct me if I'm wrong -- it would give no higher
> ranking to half-baked and would take a good deal longer on large
> indices.
> 
> 
> On Thu, 16 Dec 2004 20:03:27 +0100, Daniel Naber
> <daniel.naber@t-online.de> wrote:
> > On Thursday 16 December 2004 13:46, Mike Snare wrote:
> > 
> > > > Maybe for "a-b", but what about English words like
> "half-baked"?
> > >
> > > Perhaps that's the difference in thinking, then.  I would imagine
> that
> > > you would want to search on "half-baked" and not "half AND
> baked".
> > 
> > A search for half-baked will find both half-baked and "half baked"
> (the
> > phrase). The only thing you'll not find if halfbaked.
> > 
> > Regards
> >  Daniel
> > 
> > --
> > http://www.danielnaber.de
> > 
> >
> ---------------------------------------------------------------------
> > To unsubscribe, e-mail: lucene-user-unsubscribe@jakarta.apache.org
> > For additional commands, e-mail:
> lucene-user-help@jakarta.apache.org
> > 
> >
> 
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: lucene-user-unsubscribe@jakarta.apache.org
> For additional commands, e-mail: lucene-user-help@jakarta.apache.org
> 
> 


---------------------------------------------------------------------
To unsubscribe, e-mail: lucene-user-unsubscribe@jakarta.apache.org
For additional commands, e-mail: lucene-user-help@jakarta.apache.org


