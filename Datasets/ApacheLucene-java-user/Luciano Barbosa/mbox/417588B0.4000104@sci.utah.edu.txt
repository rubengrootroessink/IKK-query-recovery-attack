FROM: Luciano Barbosa <...@sci.utah.edu>
SUBJECT: Downloading Full Copies of Web Pages
DATE: 19 Oct 2004

Hi folks,
I want to download full copies of web pages and storage them locally as 
well the hyperlink structures as local directories. I tried to use 
Lucene, but I've realized that  it doesn't have a crawler.
Does anyone know a software that make this?
Thanks,

---------------------------------------------------------------------
To unsubscribe, e-mail: lucene-user-unsubscribe@jakarta.apache.org
For additional commands, e-mail: lucene-user-help@jakarta.apache.org


