FROM: Grant Ingersoll <gsing...@apache.org>
SUBJECT: Re: n-gram word support
DATE: 19 Jun 2009

The contrib/analyzers has several n-gram based tokenization and token  
filter options.

On Jun 18, 2009, at 10:15 PM, Neha Gupta wrote:

> Hey,
>
> I was wondering if there is a way to read the index and generate n- 
> grams of
> words for a document in lucene? I am quite new to it and am using  
> pylucene.
>
> Thanks,
> Neha

--------------------------
Grant Ingersoll
http://www.lucidimagination.com/

Search the Lucene ecosystem (Lucene/Solr/Nutch/Mahout/Tika/Droids)  
using Solr/Lucene:
http://www.lucidimagination.com/search


---------------------------------------------------------------------
To unsubscribe, e-mail: java-user-unsubscribe@lucene.apache.org
For additional commands, e-mail: java-user-help@lucene.apache.org


