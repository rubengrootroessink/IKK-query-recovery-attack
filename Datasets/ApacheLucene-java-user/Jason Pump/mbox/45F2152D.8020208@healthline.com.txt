FROM: Jason Pump <ja...@healthline.com>
SUBJECT: Re: Index a source, but not store it... can it be done?
DATE: 10 Mar 2007

Agree it's totally hackable, particularly with an md5 hashcode. If you 
used a 16 bit hash e.g. mod % 65536 then it becomes more difficult to 
construct the original document but less precise in querying. It might 
be nice to store the individual words contained in each document as just 
a sorted list, perhaps with a count, and then for doing more then one 
word queries, use documents which contain those words and doing 
proximity against the 16 bit or even 8 bit hashes, with a two word query 
and an 8 bit hash you should only get collisions 1 in 2^16, with a 16 
bit hash only 1 in 2^32. So your two word query would be something like  
'+words:word1 +words:word2 +proximityField:"237 116"~30 '.

John Haxby wrote:
> Chris Hostetter wrote:
>> i'm not crypto expert, but i imagine it would probably take the same
>> amount of statistical guess work to reconstruct meaningful info from
>> either approach (hashing hte individual words compared to eliminating 
>> the
>> positions) so i would think the trade off of supporting phrase queries
>> would make the hasing approach more worthwhile.
>>   
> hashing the words sounds like a brilliant idea, but it's subject to a 
> known plaintext attack. Basically if I have the index and a document 
> in it I can compare the reconstructed document consisting of hashed 
> words and the original document. I can then say that "cat" is 
> "d077f244def8a70e5ea758bd8352fcd8", dog is 
> "06d80eb0c50b49a509b49f2424e8c805" and so on. I then have a choice of 
> attacking the hash algorithm (there are no prizes for guessing what I 
> used) or simply constructing a table of known words and hashes.
>
> Injecting my own documents into the corpus would let me fill in 
> missing words or test an hypothesis about the hash algorithm. It would 
> be fun to see how long it would take to reconstruct the index with no 
> hashed words in it :-) The best, really, that can be said about 
> hashing is that it either piques the interest of someone who would 
> otherwise ignore it and discourages the most casual of hackers.
>
> Setting all the token positions to zero helps quite a lot because you 
> then can't distinguish between "the cat and dog sat on the mat" and 
> "the cat sat on the dog on the mat" (more or less) and one is much 
> more interesting than the other. Of course, simply knowing that there 
> are documents that contain the words, oh, "airport" and "bomb" would 
> be interesting. What would be even more interesting would be comparing 
> the index at different times -- like knowing that the Pentagon ordered 
> many more pizzas the day before the air strikes in the Gulf, that kind 
> of thing. (Langley, incidentally, ordered the same number they always 
> ordered, but perhaps fewer were put in the trash unconsumed.) (This 
> might also be an urban myth, I haven't ever seen anything definitive 
> about it.) (But I digress.)
>
> It all depends on how much value the owner of the original documents 
> places on them and how much effort he thinks that a hacker might be 
> prepared to put into recovering the text.
>
> The best you're ever going to do is to protect the index as well as 
> you do the original documents.
>
> jch
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: java-user-unsubscribe@lucene.apache.org
> For additional commands, e-mail: java-user-help@lucene.apache.org
>


-- 
Jason Pump
Technical Architect
Healthline
660 Third Street, Ste. 100
San Francisco, CA 94107
direct dial 415.281.3133
cell 510.812.1784
www.healthline.com 


---------------------------------------------------------------------
To unsubscribe, e-mail: java-user-unsubscribe@lucene.apache.org
For additional commands, e-mail: java-user-help@lucene.apache.org


