FROM: "Kevin A. Burton" <bur...@newsmonster.org>
SUBJECT: Performance when computing computing a filter using hundreds of diff terms.
DATE: 5 Aug 2004

I'm trying to compute a filter to match documents in our index by a set 
of terms.

For example some documents have a given field 'category' so I need to 
compute a filter with mulitple categories.

The problem is that our category list is > 200 items so it takes about 
80 seconds to compute.  We cache it of course but this seems WAY too slow.

Is there anything I could do to speed it up?  Maybe run the queries 
myself and then combine the bitsets?

We're using a BooleanQuery with nested TermQueries to build up the 
filter...

Kevin

-- 

Please reply using PGP.

    http://peerfear.org/pubkey.asc    
    
    NewsMonster - http://www.newsmonster.org/
    
Kevin A. Burton, Location - San Francisco, CA, Cell - 415.595.9965
       AIM/YIM - sfburtonator,  Web - http://peerfear.org/
GPG fingerprint: 5FB2 F3E2 760E 70A8 6174 D393 E84D 8D04 99F1 4412
  IRC - freenode.net #infoanarchy | #p2p-hackers | #newsmonster


---------------------------------------------------------------------
To unsubscribe, e-mail: lucene-user-unsubscribe@jakarta.apache.org
For additional commands, e-mail: lucene-user-help@jakarta.apache.org


