FROM: mark harwood <markharw...@yahoo.co.uk>
SUBJECT: RE: OutOfMemoryError while enumerating through reader.terms(fieldName)
DATE: 2 May 2006

>>Any advise is relly welcome.

Don't cache all that data.
You need a minimum of (numUniqueTerms*numDocs)/8 bytes
to hold that info.
Assuming 10,000 unique terms and 1 million docs you'd
need over 1 Gig of RAM.

I suppose the question is what are you trying to
achieve and why can't you use the existing Lucene APIs
instead of caching all those bitsets?

Cheers
Mark


		
___________________________________________________________ 
Switch an email account to Yahoo! Mail, you could win FIFA World Cup tickets. http://uk.mail.yahoo.com

---------------------------------------------------------------------
To unsubscribe, e-mail: java-user-unsubscribe@lucene.apache.org
For additional commands, e-mail: java-user-help@lucene.apache.org


